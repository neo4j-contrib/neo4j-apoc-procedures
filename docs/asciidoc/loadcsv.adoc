[[load-csv]]
== Load CSV

Many existing applications and data integrations use CSV as the minimal denominator format.

In Cypher it is supported by `LOAD CSV` and with the `neo4j-import` (`neo4j-admin import`) for bulk imports.

Usually a CSV file is text with delimiters (most often comma, but also tab (TSV) and colon (DSV)) separating columns and newlines for rows.
Fields are possibly quoted to handle stray quotes, newlines, and the use of the delimeter within a field.

The existing `LOAD CSV` works ok for most uses, but there were a few features missing, that `apoc.load.csv` and `apoc.load.xls` add.

* provide a line number
* provide both a map and a list representation of each line
* automatic data conversion (including split into arrays)
* option to keep the original string formatted values
* ignoring fields (makes it easier to assign a full line as properties)
* headerless files
* replacing certain values with null

The apoc procedures also support reading compressed files.

The data conversion is useful for setting properties directly, but for computation within Cypher it's problematic as Cypher doesn't know the type of map values so they default to `Any`.

To use them correctly, you'll have to indicate their type to Cypher by using the built-in (e.g. `toInteger`) or apoc (e.g. `apoc.convert.toBoolean`) conversion functions on the value.

For reading from files you'll have to enable the config option:

----
apoc.import.file.enabled=true
----

By default file paths are global, for paths relative to the `import` directory set:

----
apoc.import.file.use_neo4j_config=true
----

=== Examples for apoc.load.csv

.test.csv
----
name,age,beverage
Selma,9,Soda
Rana,12,Tea;Milk
Selina,19,Cola
----

----
CALL apoc.load.csv('/tmp/test.csv') yield lineNo, map, list
RETURN *;
----

----
+---------------------------------------------------------------------------------------+
| lineNo | list                       | map                                             |
+---------------------------------------------------------------------------------------+
| 0      | ["Selma", "9", "Soda"]     | {name: "Selma", age: "9", beverage: "Soda"}     |
| 1      | ["Rana", "12", "Tea;Milk"] | {name: "Rana", age: "12", beverage: "Tea;Milk"} |
| 2      | ["Selina", "19", "Cola"]   | {name: "Selina", age: "19", beverage: "Cola"}   |
+---------------------------------------------------------------------------------------+
----

=== Configuration Options

Besides the file you can pass in a config map:

[opts="autowidth,header",cols="m,m,a"]
|===
| name | default | description
| skip | none | skip result rows
| limit | none | limit result rows
| header | true | indicates if file has a header
| sep | ',' | separator character or 'TAB'
| quoteChar | '"' | the char to use for quoted elements
| arraySep | ';' | array separator
| ignore | [] | which columns to ignore
| nullValues | [] | which values to treat as null, e.g. `['na',false]`
| mapping | {} | per field mapping, entry key is field name, .e.g `{years:{....}` see below
|===

.mapping config for each field in the `mapping` entry
[opts="autowidth,header",cols="m,m,a"]
|===
| name | default | description
| type | none | 'int', 'string' etc.
| array | false | indicates if field is an array
| arraySep | ';' | separator for array
| name | none | rename field
| ignore | false | ignore/remove this field
| nullValues | [] | which values to treat as null, e.g. `['na',false]`
|===


----
CALL apoc.load.csv('/tmp/test.csv',
  {skip:1,limit:1,header:true,ignore:'name',
   mapping:{age:{type:'int'},beverage:{array:true,arraySep:';',name:'drinks'}) yield lineNo, map, list
RETURN *;
----

----
+---------------------------------------------------------------------------------------+
| lineNo | list                       | map                                             |
+---------------------------------------------------------------------------------------+
| 0      | ["Selma", "9", "Soda"]     | {name: "Selma", age: "9", beverage: "Soda"}     |
| 1      | ["Rana", "12", "Tea;Milk"] | {name: "Rana", age: "12", beverage: "Tea;Milk"} |
| 2      | ["Selina", "19", "Cola"]   | {name: "Selina", age: "19", beverage: "Cola"}   |
+---------------------------------------------------------------------------------------+
----


=== Transaction Batching

To handle large files, `USING PERIODIC COMMIT` can be prepended to `LOAD CSV`, you'll have to watch  out though for *Eager* operations which might break that behavior.

In apoc you can combine any data source with `apoc.periodic.iterate` to achieve the same.

[source,cypher]
----
CALL apoc.periodic.iterate('
CALL apoc.load.csv({url}) yield map as row return row
','
CREATE (p:Person) SET p = row
', {batchSize:10000, iterateList:true, parallel:true});
----

NOTE: Please note that the parallel operation only works well for non-conflicting updates otherwise you might run into deadlocks.

To make these datastructures available to Cypher, you can use `apoc.load.xml`.
It takes a file or http URL and parses the XML into a map datastructure.

NOTE: in previous releases we've had `apoc.load.xmlSimple`. This is now deprecated and got superseeded by
`apoc.load.xml(url, [xPath], [config], true)`.Simple XML Format

See the following usage-examples for the procedures.

[[import-csv]]
== Import CSV

CSV files that comply with the https://neo4j.com/docs/operations-manual/current/tools/import/file-header-format/[Neo4j import tool's header format] can be imported using the `apoc.import.csv` procedure. This procedure is intended to load small- to medium-sized data sets in an online database. For importing larger data sets, it is recommended to perform a batch import using the (https://neo4j.com/docs/operations-manual/current/tools/import/[import tool], which loads data in bulk to an offline (initially empty) database.

=== Usage

The parameters of the `apoc.import.csv(<nodes>, <relationships>, <config>)` procedure are as follows.

The `<nodes>` parameter is a list, where each element is a map defining a source file (`fileName`) to be loaded with a set of labels (`labels`):

[opts=header,cols="m,a,m"]
|===
| name | description | example
| fileName | filename | 'file:/students.csv'
| labels | set of labels | ['Person', 'Student']
|===

The `<relationships>` parameter is also a list, where each element is a map defining a source file (`fileName`) to be loaded with a given relationship type (`type`):

[opts=header,cols="m,a,m"]
|===
| name | description | example
| fileName | filename | 'file:/works_at.csv'
| type | relationship type | 'WORKS_AT'
|===

The `<config>` parameter is a map

[opts=header,cols="m,a,m,m"]
|===
| name | description | default | https://neo4j.com/docs/operations-manual/current/tools/import/options/[import tool counterpart]
| delimiter | delimiter character between columns | , | --delimiter=,
| arrayDelimiter | delimiter character in arrays | ; | --array-delimiter=;
| ignoreDuplicateNodes | for duplicate nodes, only load the first one and skip the rest (true) or fail the import (false) | false | --ignore-duplicate-nodes=false
| quotationCharacter | quotation character | " | --quote='"'
| stringIds | treat ids as strings | true | --id-type=STRING
| skipLines | lines to skip (incl. header) | 1 | N/A
|===

=== Examples for apoc.import.csv

==== Loading nodes

Given the following CSV file and procedure call, the database loads two `Person` nodes with their `name` properties set:

.persons.csv
----
name:STRING
John
Jane

----

[source,cypher]
----
CALL apoc.import.csv([{fileName: 'file:/persons.csv', labels: ['Person']}], [], {})
----

==== Loading nodes and relationships

Given the following CSV files and procedure call, the database loads two `Person` nodes and a `KNOWS` relationship between them (with the value of the `since` property set). Note that both the field terminators and the array delimiters are changed from the default value, and the CSVs use numeric ids.

.persons.csv
----
:ID|name:STRING|speaks:STRING[]
1|John|en,fr
2|Jane|en,de
----

.knows.csv
----
:START_ID|:END_ID|since:INT
1|2|2016
----

[source,cypher]
----
CALL apoc.import.csv(
  [{fileName: 'file:/persons.csv', labels: ['Person']}],
  [{fileName: 'file:/knows.csv', type: 'KNOWS'}],
  {delimiter: '|', arrayDelimiter: ',', stringIds: false}
)
----

The loader supports advanced features of the import tool:

* _ID spaces_ are supported, using the link:https://neo4j.com/docs/operations-manual/current/tools/import/file-header-format/#import-tool-id-spaces[import tool's syntax].
* Node labels can be specified with the link:https://neo4j.com/docs/operations-manual/current/tools/import/file-header-format/#import-tool-header-format-nodes[`:LABEL`] field.
* Relationship types can be specified with the link:https://neo4j.com/docs/operations-manual/current/tools/import/file-header-format/#import-tool-header-format-rels[`:TYPE`] field.

[[load-xls]]
== Loading Excel (XLS)

=== Library Requirements

For loading XLS we're using the Apache POI library, which works well with old and new Excel formats, but is quite large.
That's why we decided not to include it into the apoc jar, but make it an optional dependency.

Please download these jars and put them into your `plugins` directory:

For XLS files:

* http://repo1.maven.org/maven2/org/apache/poi/poi/3.17/poi-3.17.jar[poi-3.17.jar^]

Additional for XLSX files:

* http://repo1.maven.org/maven2/org/apache/commons/commons-collections4/4.1/commons-collections4-4.1.jar[commons-collections4-4.1.jar^]
* http://repo1.maven.org/maven2/org/apache/poi/poi-ooxml/3.17/poi-ooxml-3.17.jar[poi-ooxml-3.17.jar^]
* http://repo1.maven.org/maven2/org/apache/poi/poi-ooxml-schemas/3.17/poi-ooxml-schemas-3.17.jar[poi-ooxml-schemas-3.17.jar^]
* http://repo1.maven.org/maven2/org/apache/xmlbeans/xmlbeans/2.6.0/xmlbeans-2.6.0.jar[xmlbeans-2.6.0.jar^]
* http://repo1.maven.org/maven2/com/github/virtuald/curvesapi/1.04/curvesapi-1.04.jar[curvesapi-1.04.jar^]

=== Usage

The usage of `apoc.load.xls` is similar to apoc.load.csv with the main difference the ability to select a worksheet or a range from a sheet to load.

You can either select the sheet by name like `'Kids'`, or offset like `'Results!B2:F3'`

`CALL apoc.load.xls({url}, {Name of sheet}, {config})`

The `{config}` parameter is a map

[opts=header,cols="m,m"]
|===
| name | description
| mapping | {mapping:{'<sheet>':{type:'<type>', dateFormat: '<format>', dateParse: [<formats>]}}}
| <sheet> | name of the sheet
| <type> | Default `String`, The type of the conversion requested (`STRING`, `INTEGER`, `FLOAT`, `BOOLEAN`, `NULL`, `LIST`, `DATE`, `DATE_TIME`, `LOCAL_DATE`, `LOCAL_DATE_TIME`, `LOCAL_TIME`, `TIME`)
| dateFormat: <format> | Convert the Date into String (only String is allowed)
| dateParse: [<formats>] | Convert the String into Date (Array of strings are allowed)
|===

==== Note

In dateParse the first format matched return the date formatted, otherwise it will return an error

In `format` config you can use the pattern describe as the Temporal functions: link:#_temporal[temporal funcionts]

=== Examples for apoc.load.xls

[source,cypher]
----
CALL apoc.load.xls('file:///path/to/file.xls','Full',{mapping:{Integer:{type:'int'}, Array:{type:'int',array:true,arraySep:';'}}})
----

image::{img}/apoc.load.xls.png[]

[source,cypher]
----
CALL apoc.load.xls('http://bit.ly/2nXgHA2','Kids')
----

Some examples with type/dateFormat and dateParse:

[source,cypher]
----
CALL apoc.load.xls('test_date.xlsx','sheet',{mapping:{Date:{type:'String'}}})
----

.results

image::{img}/apoc.load.xls_1.png[]

[source,cypher]
----
CALL apoc.load.xls('test_date.xlsx','sheet',{mapping:{Date:{type:'String',dateFormat:'iso_date'}}})
----

.results

image::{img}/apoc.load.xls_2.png[]

[source,cypher]
----
CALL apoc.load.xls('test_date.xlsx','sheet',{mapping:{Date:{type:'String',dateParse:["wrongPath", "dd-MM-yyyy", "dd/MM/yyyy", "yyyy/MM/dd", "yyyy/dd/MM", "yyyy-dd-MM'T'hh:mm:ss"]}}})
----

.results

image::{img}/apoc.load.xls_3.png[]