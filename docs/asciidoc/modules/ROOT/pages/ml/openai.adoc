[[openai-api]]
= OpenAI API Access
:description: This section describes procedures that can be used to access the OpenAI API.

[NOTE]
====
You need to acquire an https://platform.openai.com/account/api-keys[OpenAI API key^] to use these procedures. Using them will incur costs on your OpenAI account. You can set the api key globally by defining the `apoc.openai.key` configuration in `apoc.conf`

But you can also use these procedures to call OpenAI-compatible APIs, which will therefore have their own API key (or even without API Key). 
See the paragraph <<openai_compatible_provider>> below.
====

All the following procedures can have the following APOC config, i.e. in `apoc.conf` or via docker env variable
.Apoc configuration
|===
|key | description | default
| apoc.ml.openai.type | "AZURE", "HUGGINGFACE", "OPENAI", indicates whether the API is Azure, HuggingFace or another one | "OPENAI" 
| apoc.ml.openai.url | the OpenAI endpoint base url | https://api.openai.com/v1 
    (or empty string if `apoc.ml.openai.type=<AZURE OR HUGGINGFACE>`)
| apoc.ml.azure.api.version | in case of `apoc.ml.openai.type=AZURE`, indicates the `api-version` to be passed after the `?api-version=` url
|===


Moreover, they can have the following configuration keys, as the last parameter.
If present, they take precedence over the analogous APOC configs.

.Common configuration parameter

|===
| key | description
| apiType | analogous to `apoc.ml.openai.type` APOC config
| endpoint | analogous to `apoc.ml.openai.url` APOC config
| apiVersion | analogous to `apoc.ml.azure.api.version` APOC config
| path | To customize the url portion added to the base url (defined by the `endpoint` config).
    By default, is `/embeddings`, `/completions` and `/chat/completions` for respectively the `apoc.ml.openai.embedding`, `apoc.ml.openai.completion` and `apoc.ml.openai.chat` procedures.
| jsonPath | To customize https://github.com/json-path/JsonPath[JSONPath] of the response. 
    The default is `$` for the `apoc.ml.openai.chat` and `apoc.ml.openai.completion` procedures, and `$.data` for the `apoc.ml.openai.embedding` procedure.
|===


Therefore, we can use the following procedures with the Open AI Services provided by Azure,
pointing to the correct endpoints https://learn.microsoft.com/it-it/azure/ai-services/openai/reference[as explained in the documentation].

That is, if we want to call an endpoint like https://my-resource.openai.azure.com/openai/deployments/my-deployment-id/embeddings?api-version=my-api-version` for example,
by passing as a configuration parameter:
```
    {endpoint: "https://my-resource.openai.azure.com/openai/deployments/my-deployment-id",
        apiVersion: my-api-version,
        apiType: 'AZURE'
}
```

The `/embeddings` portion will be added under-the-hood.
Similarly, if we use the `apoc.ml.openai.completion`,  if we want to call an endpoint like `https://my-resource.openai.azure.com/openai/deployments/my-deployment-id/completions?api-version=my-api-version` for example,
we can write the same configuration parameter as above,
where the `/completions` portion will be added.

While using the `apoc.ml.openai.chat`, with the same configuration, the url portion `/chat/completions` will be added

Or else, we can write this `apoc.conf`:
```
apoc.ml.openai.url=https://my-resource.openai.azure.com/openai/deployments/my-deployment-id
apoc.ml.azure.api.version=my-api-version
apoc.ml.openai.type=AZURE
```



== Generate Embeddings API

This procedure `apoc.ml.openai.embedding` can take a list of text strings, and will return one row per string, with the embedding data as a 1536 element vector.
It uses the `/embeddings/create` API which is https://platform.openai.com/docs/api-reference/embeddings/create[documented here^].

Additional configuration is passed to the API, the default model used is `text-embedding-ada-002`.

.Generate Embeddings Call
[source,cypher]
----
CALL apoc.ml.openai.embedding(['Some Text'], $apiKey, {}) yield index, text, embedding;
----

.Generate Embeddings Response
[%autowidth, opts=header]
|===
|index | text | embedding
|0 | "Some Text" | [-0.0065358975, -7.9563365E-4, .... -0.010693862, -0.005087272]
|===

.Parameters
[%autowidth, opts=header]
|===
|name | description
| texts | List of text strings
| apiKey | OpenAI API key
| configuration | optional map for entries like model and other request parameters.

    We can also pass a custom `endpoint: <MyAndPointKey>` entry (it takes precedence over the `apoc.ml.openai.url` config).
    The `<MyAndPointKey>` can be the complete andpoint (e.g. using Azure: `https://my-resource.openai.azure.com/openai/deployments/my-deployment-id/chat/completions?api-version=my-api-version`),
    or with a `%s` (e.g. using Azure: `https://my-resource.openai.azure.com/openai/deployments/my-deployment-id/%s?api-version=my-api-version`) which will eventually be replaced with `embeddings`, `chat/completion` and `completion` 
    by using respectively the `apoc.ml.openai.embedding`, `apoc.ml.openai.chat` and `apoc.ml.openai.completion`.

    Or an `authType: `AUTH_TYPE`, which can be `authType: "BEARER"` (default config.), to pass the apiKey via the header as an `Authorization: Bearer $apiKey`,
        or `authType: "API_KEY"` to pass the apiKey as an `api-key: $apiKey` header entry.
|===


.Results
[%autowidth, opts=header]
|===
|name | description
| index | index entry in original list
| text  | line of text from original list
| embedding | 1536 element floating point embedding vector for ada-002 model
|===

== Text Completion API

This procedure `apoc.ml.openai.completion` can continue/complete a given text.

It uses the `/completions/create` API which is https://platform.openai.com/docs/api-reference/completions/create[documented here^].

Additional configuration is passed to the API, the default model used is `text-davinci-003`.

.Text Completion Call
[source,cypher]
----
CALL apoc.ml.openai.completion('What color is the sky? Answer in one word: ', $apiKey, {config}) yield value;
----

.Text Completion Response
----
{ created=1684248202, model="text-davinci-003", id="cmpl-7GqBWwX49yMJljdmnLkWxYettZoOy",
  usage={completion_tokens=2, prompt_tokens=12, total_tokens=14},
  choices=[{finish_reason="stop", index=0, text="Blue", logprobs=null}], object="text_completion"}
----

.Parameters
[%autowidth, opts=header]
|===
|name | description
| prompt | Text to complete
| apiKey | OpenAI API key
| configuration | optional map for entries like model, temperature, and other request parameters
|===

.Results
[%autowidth, opts=header]
|===
|name | description
| value | result entry from OpenAI (containing)
|===


=== OpenLM API

We can also call the Completion API of HuggingFace and Cohere, similar to the https://github.com/r2d4/openlm[OpenLM] library, as below.

For the https://huggingface.co/[HuggingFace API], we have to define the config `apiType: 'HUGGINGFACE'`, since we have to transform the body request.

For example:
[source,cypher]
----
CALL apoc.ml.openai.completion('What color is the sky? Answer in one word: ', $huggingFaceApiKey, 
{endpoint: 'https://api-inference.huggingface.co/models/gpt2', apiType: 'HUGGINGFACE', model: 'gpt2', path: ''})
----

Or also, by using the https://docs.cohere.com/docs[Cohere API], where we have to define `path: '''` not to add the `/completions` suffix to the URL:
[source,cypher]
----
CALL apoc.ml.openai.completion('What color is the sky? Answer in one word: ', $cohereApiKey, 
{endpoint: 'https://api.cohere.ai/v1/generate', path: '', model: 'command'})
----


== Chat Completion API

This procedure `apoc.ml.openai.chat` takes a list of maps of chat exchanges between assistant and user (with optional system message), and will return the next message in the flow.

It uses the `/chat/create` API which is https://platform.openai.com/docs/api-reference/chat/create[documented here^].

Additional configuration is passed to the API, the default model used is `gpt-3.5-turbo`.

.Chat Completion Call
[source,cypher]
----
CALL apoc.ml.openai.chat([
{role:"system", content:"Only answer with a single word"},
{role:"user", content:"What planet do humans live on?"}
],  $apiKey) yield value
----

.Chat Completion Response
----
{created=1684248203, id="chatcmpl-7GqBXZr94avd4fluYDi2fWEz7DIHL",
object="chat.completion", model="gpt-3.5-turbo-0301",
usage={completion_tokens=2, prompt_tokens=26, total_tokens=28},
choices=[{finish_reason="stop", index=0, message={role="assistant", content="Earth."}}]}
----

.Parameters
[%autowidth, opts=header]
|===
|name | description
| messages | List of maps of instructions with `{role:"assistant\|user\|system", content:"text}`
| apiKey | OpenAI API key
| configuration | optional map for entries like model, temperature, and other request parameters
|===

.Results
[%autowidth, opts=header]
|===
|name | description
| value | result entry from OpenAI (containing created, id, model, object, usage(tokens), choices(message, index, finish_reason))
|===


[[openai_compatible_provider]]
== OpenAI-compatible provider

We can also use these procedures to call OpenAI-compatible APIs,
by defining the `endpoint` config, and possibly the `model`, `path` and `jsonPath` configs.

For example, we can call the https://app.endpoints.anyscale.com/[Anyscale Endpoints]:
[source,cypher]
----
CALL apoc.ml.openai.embedding(['Some Text'], $anyScaleApiKey, 
{endpoint: 'https://api.endpoints.anyscale.com/v1', model: 'thenlper/gte-large'})
----


Or via https://localai.io/[LocalAI APIs] (note that the apiKey is `null` by default):
[source,cypher]
----
CALL apoc.ml.openai.embedding(['Some Text'], "ignored", 
{endpoint: 'http://localhost:8080/v1', model: 'text-embedding-ada-002'})
----

Or also, by using https://github.com/fardjad/node-llmatic[LLMatic Library]:
[source,cypher]
----
CALL apoc.ml.openai.embedding(['Some Text'], "ignored", 
{endpoint: 'http://localhost:3000/v1', model: 'thenlper/gte-large'})
----

Furthermore, we can use the https://console.groq.com/docs/quickstart[Groq API], e.g.:
[source,cypher]
----
CALL apoc.ml.openai.chat([{"role": "user", "content": "Explain the importance of low latency LLMs"}], 
    '<apiKey>',
    {endpoint: 'https://api.groq.com/openai/v1', model: 'mixtral-8x7b-32768'})
----


== Query with natural language

This procedure `apoc.ml.query` takes a question in natural language and returns the results of that query.

It uses the `chat/completions` API which is https://platform.openai.com/docs/api-reference/chat/create[documented here^].

.Query call
[source,cypher]
----
CALL apoc.ml.query("What movies did Tom Hanks play in?") yield value, query
RETURN *
----

.Example response
[source, bash]
----
+------------------------------------------------------------------------------------------------------------------------------+
| value                                 | query                                                                                |
+------------------------------------------------------------------------------------------------------------------------------+
| {m.title -> "You've Got Mail"}        | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "Apollo 13"}              | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "Joe Versus the Volcano"} | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "That Thing You Do"}      | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "Cloud Atlas"}            | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "The Da Vinci Code"}      | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "Sleepless in Seattle"}   | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "A League of Their Own"}  | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "The Green Mile"}         | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "Charlie Wilson's War"}   | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "Cast Away"}              | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
| {m.title -> "The Polar Express"}      | "cypher
MATCH (m:Movie)<-[:ACTED_IN]-(p:Person {name: 'Tom Hanks'})
RETURN m.title
" |
+------------------------------------------------------------------------------------------------------------------------------+
12 rows
----

.Input Parameters
[%autowidth, opts=header]
|===
| name | description
| question | The question in the natural language
| conf | An optional configuration map, please check the next section | no
|===

.Configuration map
[%autowidth, opts=header]
|===
| name | description | mandatory
| retries | The number of retries in case of API call failures | no, default `3`
| retryWithError | If true, in case of error retry the api adding the following messages to the body request:
{`"role":"user", "content": "The previous Cypher Statement throws the following error, consider it to return the correct statement: `<errorMessage>`"}, {"role":"assistant", "content":"Cypher Statement (in backticks):"}` | no, default `false`
| apiKey | OpenAI API key | in case `apoc.openai.key` is not defined
| model | The Open AI model | no, default `gpt-3.5-turbo`
| sample | The number of nodes to skip, e.g. a sample of 1000 will read every 1000th node. It's used as a parameter to `apoc.meta.data` procedure that computes the schema | no, default is a random number
|===

.Results
[%autowidth, opts=header]
|===
| name | description
| value | the result of the query
| cypher | the query used to compute the result
|===


== Describe the graph model with natural language

This procedure `apoc.ml.schema` returns a description, in natural language, of the underlying dataset.

It uses the `chat/completions` API which is https://platform.openai.com/docs/api-reference/chat/create[documented here^].

.Query call
[source,cypher]
----
CALL apoc.ml.schema() yield value
RETURN *
----

.Example response
[source, bash]
----
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| "The graph database schema represents a system where users can follow other users and review movies. Users (:Person) can either follow other users (:Person) or review movies (:Movie). The relationships allow users to express their preferences and opinions about movies. This schema can be compared to social media platforms where users can follow each other and leave reviews or ratings for movies they have watched. It can also be related to movie recommendation systems where user preferences and reviews play a crucial role in generating personalized recommendations." |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
1 row
----

.Input Parameters
[%autowidth, opts=header]
|===
| name | description
| conf | An optional configuration map, please check the next section
|===

.Configuration map
[%autowidth, opts=header]
|===
| name | description | mandatory
| apiKey | OpenAI API key | in case `apoc.openai.key` is not defined
| model | The Open AI model | no, default `gpt-3.5-turbo`
| sample | The number of nodes to skip, e.g. a sample of 1000 will read every 1000th node. It's used as a parameter to `apoc.meta.data` procedure that computes the schema | no, default is a random number
|===

.Results
[%autowidth, opts=header]
|===
| name | description
| value | the description of the dataset
|===


== Create cypher queries from a natural language query

This procedure `apoc.ml.cypher` takes a natural language question and transforms it into a number of requested cypher queries.

It uses the `chat/completions` API which is https://platform.openai.com/docs/api-reference/chat/create[documented here^].

.Query call
[source,cypher]
----
CALL apoc.ml.cypher("Who are the actors which also directed a movie?", {count: 4}) yield cypher
RETURN *
----

.Example response
[source, bash]
----
+----------------------------------------------------------------------------------------------------------------+
| query                                                                                                          |
+----------------------------------------------------------------------------------------------------------------+
| "
MATCH (a:Person)-[:ACTED_IN]->(m:Movie)<-[:DIRECTED]-(d:Person)
RETURN a.name as actor, d.name as director
" |
| "cypher
MATCH (a:Person)-[:ACTED_IN]->(m:Movie)<-[:DIRECTED]-(a)
RETURN a.name
"                               |
| "
MATCH (a:Person)-[:ACTED_IN]->(m:Movie)<-[:DIRECTED]-(d:Person)
RETURN a.name
"                              |
| "cypher
MATCH (a:Person)-[:ACTED_IN]->(:Movie)<-[:DIRECTED]-(a)
RETURN DISTINCT a.name
"                       |
+----------------------------------------------------------------------------------------------------------------+
4 rows
----

.Input Parameters
[%autowidth, opts=header]
|===
| name | description | mandatory
| question | The question in the natural language | yes
| conf | An optional configuration map, please check the next section | no
|===

.Configuration map
[%autowidth, opts=header]
|===
| name | description | mandatory
| count | The number of queries to retrieve | no, default `1`
| apiKey | OpenAI API key | in case `apoc.openai.key` is not defined
| model | The Open AI model | no, default `gpt-3.5-turbo`
| sample | The number of nodes to skip, e.g. a sample of 1000 will read every 1000th node. It's used as a parameter to `apoc.meta.data` procedure that computes the schema | no, default is a random number
|===

.Results
[%autowidth, opts=header]
|===
| name | description
| value | the description of the dataset
|===

== Create a natural language query explanation from a cypher query

This procedure `apoc.ml.fromCypher` takes a natural language question and transforms it into natural language query explanation.

It uses the `chat/completions` API which is https://platform.openai.com/docs/api-reference/chat/create[documented here^].

.Query call
[source,cypher]
----
CALL apoc.ml.cypher("MATCH (p:Person {name: "Tom Hanks"})-[:ACTED_IN]->(m:Movie) RETURN m", {}) yield value
RETURN *
----

.Example response
[opts="header"]
|===
| value
| this database schema represents a simplified version of a common movie database model. the `movie` node represents a movie entity with attributes such as the year it was released, a tagline, and the movie title. the `person` node represents a person involved in the movie industry, with attributes for the person's year of birth and name. the relationship `directed` connects a `person` node to a `movie` node, indicating that the person directed the movie.
in terms of domains, this schema can be related to the entertainment industry, specifically the movie industry. movies and people involved in creating those movies are fundamental entities in this domain. the `directed` relationship captures the directed-by relationship between a person and a movie. this type of model can be extended to include other relationships like `acted_in`, `produced`, `wrote`, etc., to capture more complex connections within the movie industry.
overall, this graph database schema provides a simple yet powerful representation of entities and relationships in the movie domain, allowing for querying and analysis of connections within the industry.
|===

.Input Parameters
[%autowidth, opts=header]
|===
| name | description | mandatory
| cypher | The question in the natural language | yes
| conf | An optional configuration map, please check the next section | no
|===

.Configuration map
[%autowidth, opts=header]
|===
| name | description | mandatory
| retries | The number of retries in case of API call failures | no, default `3`
| apiKey | OpenAI API key | in case `apoc.openai.key` is not defined
| model | The Open AI model | no, default `gpt-3.5-turbo`
| sample | The number of nodes to skip, e.g. a sample of 1000 will read every 1000th node. It's used as a parameter to `apoc.meta.data` procedure that computes the schema | no, default is a random number
|===


.Results
[%autowidth, opts=header]
|===
| name | description
| value | the description of the dataset
|===


== Create explanation of the subgraph from a set of queries

This procedure `apoc.ml.fromQueries` returns an explanation, in natural language, of the given set of queries.

It uses the `chat/completions` API which is https://platform.openai.com/docs/api-reference/chat/create[documented here^].

.Query call
[source,cypher]
----
CALL apoc.ml.fromQueries(['MATCH (n:Movie) RETURN n', 'MATCH (n:Person) RETURN n'], 
    {apiKey: <apiKey>}) 
YIELD value
RETURN *
----

.Example response
[source, bash]
----
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| "The database represents movies and people, like in a movie database or social network.
    There are no defined relationships between nodes, allowing flexibility for future connections.
    The Movie node includes properties like title, tagline, and release year." |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
1 row
----

.Query call with path
[source,cypher]
----
CALL apoc.ml.fromQueries(['MATCH (n:Movie) RETURN n', 'MATCH p=(n:Movie)--() RETURN p'], 
    {apiKey: <apiKey>}) 
YIELD value
RETURN *
----

.Example response
[source, bash]
----
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| "models relationships in the movie industry, connecting :Person nodes to :Movie nodes. 
    It represents actors, directors, writers, producers, and reviewers connected to movies they are involved with.
    Similar to a social network graph but specialized for the entertainment industry.
    Each relationship type corresponds to common roles in movie production and reviewing.
    Allows for querying and analyzing connections and collaborations within the movie business." |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
1 row
----


.Input Parameters
[%autowidth, opts=header]
|===
| name | description
| queries | The list of queries
| conf | An optional configuration map, please check the next section
|===

.Configuration map
[%autowidth, opts=header]
|===
| name | description | mandatory
| apiKey | OpenAI API key | in case `apoc.openai.key` is not defined
| model | The Open AI model | no, default `gpt-3.5-turbo`
| sample | The number of nodes to skip, e.g. a sample of 1000 will read every 1000th node. It's used as a parameter to `apoc.meta.data` procedure that computes the schema | no, default is a random number
|===

.Results
[%autowidth, opts=header]
|===
| name | description
| value | the description of the dataset
|===