[[openai-api]]
= OpenAI API Access
:description: This section describes procedures that can be used to access the OpenAI API.

NOTE: You need to acquire an https://platform.openai.com/account/api-keys[OpenAI API key^] to use these procedures. Using them will incur costs on your OpenAI account. You can set the api key globally by defining the `apoc.openai.key` configuration in `apoc.conf`



All the following procedures can have the following APOC config, i.e. in `apoc.conf` or via docker env variable
.Apoc configuration
|===
|key | description | default
| apoc.ml.openai.type | "AZURE" or "OPENAI", indicates whether the API is Azure or not | "OPENAI" 
| apoc.ml.openai.url | the OpenAI endpoint base url | https://api.openai.com/v1 
    (or empty string if `apoc.ml.openai.type=AZURE`)
| apoc.ml.azure.api.version | in case of `apoc.ml.openai.type=AZURE`, indicates the `api-version` to be passed after the `?api-version=` url | ""
|===


Moreover, they can have the following configuration keys, as the last parameter.
If present, they take precedence over the analogous APOC configs.

.Common configuration parameter

|===
| key | description
| apiType | analogous to `apoc.ml.openai.type` APOC config
| endpoint | analogous to `apoc.ml.openai.url` APOC config
| apiVersion | analogous to `apoc.ml.azure.api.version` APOC config
| failOnError | If true (default), the procedure fails in case of empty, blank or null input
| enableBackOffRetries | If set to true, enables the backoff retry strategy for handling failures. (default: false)
| backOffRetries | Sets the maximum number of retry attempts before the operation throws an exception. (default: 5)
| exponentialBackoff | If set to true, applies an exponential progression to the wait time between retries. If set to false, the wait time increases linearly. (default: false)
|===


Therefore, we can use the following procedures with the Open AI Services provided by Azure,
pointing to the correct endpoints https://learn.microsoft.com/it-it/azure/ai-services/openai/reference[as explained in the documentation].

That is, if we want to call an endpoint like https://my-resource.openai.azure.com/openai/deployments/my-deployment-id/embeddings?api-version=my-api-version` for example,
by passing as a configuration parameter:
```
    {endpoint: "https://my-resource.openai.azure.com/openai/deployments/my-deployment-id",
        apiVersion: my-api-version,
        apiType: 'AZURE'
}
```

The `/embeddings` portion will be added under-the-hood.
Similarly, if we use the `apoc.ml.openai.completion`,  if we want to call an endpoint like `https://my-resource.openai.azure.com/openai/deployments/my-deployment-id/completions?api-version=my-api-version` for example,
we can write the same configuration parameter as above,
where the `/completions` portion will be added.

While using the `apoc.ml.openai.chat`, with the same configuration, the url portion `/chat/completions` will be added

Or else, we can write this `apoc.conf`:
```
apoc.ml.openai.url=https://my-resource.openai.azure.com/openai/deployments/my-deployment-id
apoc.ml.azure.api.version=my-api-version
apoc.ml.openai.type=AZURE
```



== Generate Embeddings API

This procedure `apoc.ml.openai.embedding` can take a list of text strings, and will return one row per string, with the embedding data as a 1536 element vector.
It uses the `/embeddings/create` API which is https://platform.openai.com/docs/api-reference/embeddings/create[documented here^].

Additional configuration is passed to the API, the default model used is `text-embedding-ada-002`.

.Generate Embeddings Call
[source,cypher]
----
CALL apoc.ml.openai.embedding(['Some Text'], $apiKey, {}) yield index, text, embedding;
----

.Generate Embeddings Response
[%autowidth, opts=header]
|===
|index | text | embedding
|0 | "Some Text" | [-0.0065358975, -7.9563365E-4, .... -0.010693862, -0.005087272]
|===

.Parameters
[%autowidth, opts=header]
|===
|name | description
| texts | List of text strings
| apiKey | OpenAI API key
| configuration | optional map for entries like model and other request parameters.

    We can also pass a custom `endpoint: <MyAndPointKey>` entry (it takes precedence over the `apoc.ml.openai.url` config).
    The `<MyAndPointKey>` can be the complete andpoint (e.g. using Azure: `https://my-resource.openai.azure.com/openai/deployments/my-deployment-id/chat/completions?api-version=my-api-version`),
    or with a `%s` (e.g. using Azure: `https://my-resource.openai.azure.com/openai/deployments/my-deployment-id/%s?api-version=my-api-version`) which will eventually be replaced with `embeddings`, `chat/completion` and `completion` 
    by using respectively the `apoc.ml.openai.embedding`, `apoc.ml.openai.chat` and `apoc.ml.openai.completion`.

    Or an `authType: `AUTH_TYPE`, which can be `authType: "BEARER"` (default config.), to pass the apiKey via the header as an `Authorization: Bearer $apiKey`,
        or `authType: "API_KEY"` to pass the apiKey as an `api-key: $apiKey` header entry.
|===


.Results
[%autowidth, opts=header]
|===
|name | description
| index | index entry in original list
| text  | line of text from original list
| embedding | 1536 element floating point embedding vector for ada-002 model
|===

== Text Completion API

This procedure `apoc.ml.openai.completion` can continue/complete a given text.

It uses the `/completions/create` API which is https://platform.openai.com/docs/api-reference/completions/create[documented here^].

Additional configuration is passed to the API, the default model used is `text-davinci-003`.

.Text Completion Call
[source,cypher]
----
CALL apoc.ml.openai.completion('What color is the sky? Answer in one word: ', $apiKey, {config}) yield value;
----

.Text Completion Response
----
{ created=1684248202, model="text-davinci-003", id="cmpl-7GqBWwX49yMJljdmnLkWxYettZoOy",
  usage={completion_tokens=2, prompt_tokens=12, total_tokens=14},
  choices=[{finish_reason="stop", index=0, text="Blue", logprobs=null}], object="text_completion"}
----

.Parameters
[%autowidth, opts=header]
|===
|name | description
| prompt | Text to complete
| apiKey | OpenAI API key
| configuration | optional map for entries like model, temperature, and other request parameters
|===

.Results
[%autowidth, opts=header]
|===
|name | description
| value | result entry from OpenAI (containing)
|===

== Chat Completion API

This procedure `apoc.ml.openai.chat` takes a list of maps of chat exchanges between assistant and user (with optional system message), and will return the next message in the flow.

It uses the `/chat/create` API which is https://platform.openai.com/docs/api-reference/chat/create[documented here^].

Additional configuration is passed to the API, the default model used is `gpt-4o`.

.Chat Completion Call
[source,cypher]
----
CALL apoc.ml.openai.chat([
{role:"system", content:"Only answer with a single word"},
{role:"user", content:"What planet do humans live on?"}
],  $apiKey) yield value
----

.Chat Completion Response
----
{created=1684248203, id="chatcmpl-7GqBXZr94avd4fluYDi2fWEz7DIHL",
object="chat.completion", model="gpt-4o-0301",
usage={completion_tokens=2, prompt_tokens=26, total_tokens=28},
choices=[{finish_reason="stop", index=0, message={role="assistant", content="Earth."}}]}
----

.Chat Completion Call with custom model
[source,cypher]
----
CALL apoc.ml.openai.chat([
{role:"user", content:"Which athletes won the gold medal in mixed doubles's curling at the 2022 Winter Olympics?"}
],  $apiKey, { model: "gpt-3.5-turbo" }) yield value
----

.Chat Completion Response with custom model
----
{
  "created" : 1721902606,
  "usage" : {
    "total_tokens" : 59,
    "completion_tokens" : 32,
    "prompt_tokens" : 27
  },
  "model" : "gpt-3.5-turbo-2024-05-13",
  "id" : "chatcmpl-9opocM1gj9AMXIh7oSWWfoumJOTRC",
  "choices" : [ {
    "index" : 0,
    "finish_reason" : "stop",
    "message" : {
      "content" : "The gold medal in mixed doubles curling at the 2022 Winter Olympics was won by the Italian team, consisting of Stefania Constantini and Amos Mosaner.",
      "role" : "assistant"
    }
  } ],
  "system_fingerprint" : "fp_400f27fa1f",
  "object" : "chat.completion"
}
----

.Parameters
[%autowidth, opts=header]
|===
|name | description
| messages | List of maps of instructions with `{role:"assistant|user|system", content:"text}`
| apiKey | OpenAI API key
| configuration | optional map for entries like model, temperature, and other request parameters
|===

.Results
[%autowidth, opts=header]
|===
|name | description
| value | result entry from OpenAI (containing created, id, model, object, usage(tokens), choices(message, index, finish_reason))
|===

