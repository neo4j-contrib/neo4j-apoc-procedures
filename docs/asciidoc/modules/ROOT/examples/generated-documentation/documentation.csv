¦type¦qualified name¦signature¦description¦core¦documentation
¦procedure¦apoc.bolt.execute¦apoc.bolt.execute(url :: STRING?, kernelTransaction :: STRING?, params = {} :: MAP?, config = {} :: MAP?) :: (row :: MAP?)¦apoc.bolt.execute(url-or-key, kernelTransaction, params, config) - access to other databases via bolt for reads and writes¦false¦xref::database-integration/bolt-neo4j.adoc
¦procedure¦apoc.bolt.load¦apoc.bolt.load(url :: STRING?, kernelTransaction :: STRING?, params = {} :: MAP?, config = {} :: MAP?) :: (row :: MAP?)¦apoc.bolt.load(url-or-key, kernelTransaction, params, config) - access to other databases via bolt for read¦false¦xref::database-integration/bolt-neo4j.adoc
¦procedure¦apoc.bolt.load.fromLocal¦apoc.bolt.load.fromLocal(url :: STRING?, localStatement :: STRING?, remoteStatement :: STRING?, config = {} :: MAP?) :: (row :: MAP?)¦¦false¦xref::database-integration/bolt-neo4j.adoc
¦procedure¦apoc.config.list¦apoc.config.list() :: (key :: STRING?, value :: ANY?)¦apoc.config.list | Lists the Neo4j configuration as key,value table¦false¦xref::database-introspection/config.adoc
¦procedure¦apoc.config.map¦apoc.config.map() :: (value :: MAP?)¦apoc.config.map | Lists the Neo4j configuration as map¦false¦xref::database-introspection/config.adoc
¦procedure¦apoc.couchbase.append¦apoc.couchbase.append(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, content :: BYTEARRAY?, config = {} :: MAP?) :: (content :: BYTEARRAY?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)¦apoc.couchbase.append(hostOrKey, bucket, documentId, content, config) yield id, expiry, cas, mutationToken, content - append a couchbase json document to an existing one.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.exists¦apoc.couchbase.exists(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, config = {} :: MAP?) :: (value :: BOOLEAN?)¦apoc.couchbase.exists(hostOrKey, bucket, documentId, config) yield value - check whether a couchbase json document with the given ID does exist.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.get¦apoc.couchbase.get(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)¦apoc.couchbase.get(hostOrKey, bucket, documentId, config) yield id, expiry, cas, mutationToken, content - retrieves a couchbase json document by its unique ID.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.insert¦apoc.couchbase.insert(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, json :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)¦apoc.couchbase.insert(hostOrKey, bucket, documentId, jsonDocument, config) yield id, expiry, cas, mutationToken, content - insert a couchbase json document with its unique ID.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.namedParamsQuery¦apoc.couchbase.namedParamsQuery(hostOrKey :: STRING?, bucket :: STRING?, statement :: STRING?, paramNames :: LIST? OF STRING?, paramValues :: LIST? OF ANY?, config = {} :: MAP?) :: (queryResult :: LIST? OF MAP?)¦apoc.couchbase.namedParamsQuery(hostkOrKey, bucket, statement, paramNames, paramValues, config) yield queryResult - executes a N1QL statement with named parameters.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.posParamsQuery¦apoc.couchbase.posParamsQuery(hostOrKey :: STRING?, bucket :: STRING?, statement :: STRING?, params :: LIST? OF ANY?, config = {} :: MAP?) :: (queryResult :: LIST? OF MAP?)¦apoc.couchbase.posParamsQuery(hostOrKey, bucket, statement, params, config) yield queryResult - executes a N1QL statement with positional parameters.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.prepend¦apoc.couchbase.prepend(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, content :: BYTEARRAY?, config = {} :: MAP?) :: (content :: BYTEARRAY?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)¦apoc.couchbase.prepend(hostOrKey, bucket, documentId, content, config) yield id, expiry, cas, mutationToken, content - prepend a couchbase json document to an existing one.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.query¦apoc.couchbase.query(hostOrKey :: STRING?, bucket :: STRING?, statement :: STRING?, config = {} :: MAP?) :: (queryResult :: LIST? OF MAP?)¦apoc.couchbase.query(hostOrKey, bucket, statement, config) yield queryResult - executes a plain un-parameterized N1QL statement.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.remove¦apoc.couchbase.remove(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)¦apoc.couchbase.remove(hostOrKey, bucket, documentId, config) yield id, expiry, cas, mutationToken, content - remove the couchbase json document identified by its unique ID.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.replace¦apoc.couchbase.replace(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, json :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)¦apoc.couchbase.replace(hostOrKey, bucket, documentId, jsonDocument, config) yield id, expiry, cas, mutationToken, content - replace the content of the couchbase json document identified by its unique ID.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.couchbase.upsert¦apoc.couchbase.upsert(hostOrKey :: STRING?, bucket :: STRING?, documentId :: STRING?, json :: STRING?, config = {} :: MAP?) :: (content :: MAP?, id :: STRING?, expiry :: INTEGER?, cas :: INTEGER?, mutationToken :: MAP?)¦apoc.couchbase.upsert(hostOrKey, bucket, documentId, jsonDocument) yield id, expiry, cas, mutationToken, content - insert or overwrite a couchbase json document with its unique ID.¦false¦xref::database-integration/couchbase.adoc
¦procedure¦apoc.custom.declareFunction¦apoc.custom.declareFunction(signature :: STRING?, statement :: STRING?, forceSingle = false :: BOOLEAN?, description =  :: STRING?) :: VOID¦apoc.custom.declareFunction(signature, statement, forceSingle, description) - register a custom cypher function¦false¦xref::cypher-execution/cypher-based-procedures-functions.adoc
¦procedure¦apoc.custom.declareProcedure¦apoc.custom.declareProcedure(signature :: STRING?, statement :: STRING?, mode = read :: STRING?, description =  :: STRING?) :: VOID¦apoc.custom.declareProcedure(signature, statement, mode, description) - register a custom cypher procedure¦false¦xref::cypher-execution/cypher-based-procedures-functions.adoc
¦procedure¦apoc.custom.list¦apoc.custom.list() :: (type :: STRING?, name :: STRING?, description :: STRING?, mode :: STRING?, statement :: STRING?, inputs :: LIST? OF LIST? OF STRING?, outputs :: ANY?, forceSingle :: BOOLEAN?)¦apoc.custom.list() - provide a list of custom procedures/function registered¦false¦xref::cypher-execution/cypher-based-procedures-functions.adoc
¦procedure¦apoc.custom.removeFunction¦apoc.custom.removeFunction(name :: STRING?) :: VOID¦apoc.custom.removeFunction(name, type) - remove the targeted custom function¦false¦xref::cypher-execution/cypher-based-procedures-functions.adoc
¦procedure¦apoc.custom.removeProcedure¦apoc.custom.removeProcedure(name :: STRING?) :: VOID¦apoc.custom.removeProcedure(name) - remove the targeted custom procedure¦false¦xref::cypher-execution/cypher-based-procedures-functions.adoc
¦procedure¦apoc.cypher.mapParallel¦apoc.cypher.mapParallel(fragment :: STRING?, params :: MAP?, list :: LIST? OF ANY?) :: (value :: MAP?)¦apoc.cypher.mapParallel(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _¦false¦xref::cypher-execution/index.adoc
¦procedure¦apoc.cypher.mapParallel2¦apoc.cypher.mapParallel2(fragment :: STRING?, params :: MAP?, list :: LIST? OF ANY?, partitions :: INTEGER?, timeout = 10 :: INTEGER?) :: (value :: MAP?)¦apoc.cypher.mapParallel2(fragment, params, list-to-parallelize) yield value - executes fragment in parallel batches with the list segments being assigned to _¦false¦xref::cypher-execution/index.adoc
¦procedure¦apoc.cypher.parallel¦apoc.cypher.parallel(fragment :: STRING?, params :: MAP?, parallelizeOn :: STRING?) :: (value :: MAP?)¦apoc.cypher.parallel(fragment, `paramMap`, `keyList`) yield value - executes fragments in parallel through a list defined in `paramMap` with a key `keyList`¦false¦xref::cypher-execution/index.adoc
¦procedure¦apoc.cypher.parallel2¦apoc.cypher.parallel2(fragment :: STRING?, params :: MAP?, parallelizeOn :: STRING?) :: (value :: MAP?)¦apoc.cypher.parallel2(fragment, `paramMap`, `keyList`) yield value - executes fragments in parallel batches through a list defined in `paramMap` with a key `keyList`¦false¦xref::cypher-execution/index.adoc
¦procedure¦apoc.cypher.runFile¦apoc.cypher.runFile(file :: STRING?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)¦apoc.cypher.runFile(file or url,[{statistics:true,timeout:10,parameters:{}}]) - runs each statement in the file, all semicolon separated - currently no schema operations¦false¦xref::cypher-execution/index.adoc
¦procedure¦apoc.cypher.runFiles¦apoc.cypher.runFiles(file :: LIST? OF STRING?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)¦apoc.cypher.runFiles([files or urls],[{statistics:true,timeout:10,parameters:{}}])) - runs each statement in the files, all semicolon separated¦false¦xref::cypher-execution/index.adoc
¦procedure¦apoc.cypher.runSchemaFile¦apoc.cypher.runSchemaFile(file :: STRING?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)¦apoc.cypher.runSchemaFile(file or url,[{statistics:true,timeout:10}]) - allows only schema operations, runs each schema statement in the file, all semicolon separated¦false¦xref::cypher-execution/index.adoc
¦procedure¦apoc.cypher.runSchemaFiles¦apoc.cypher.runSchemaFiles(file :: LIST? OF STRING?, config = {} :: MAP?) :: (row :: INTEGER?, result :: MAP?)¦apoc.cypher.runSchemaFiles([files or urls],{statistics:true,timeout:10}) - allows only schema operations, runs each schema statement in the files, all semicolon separated¦false¦xref::cypher-execution/index.adoc
¦procedure¦apoc.es.get¦apoc.es.get(host :: STRING?, index :: STRING?, type :: STRING?, id :: STRING?, query :: ANY?, payload :: ANY?) :: (value :: MAP?)¦apoc.es.get(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a GET operation on elastic search¦false¦xref::database-integration/elasticsearch.adoc
¦procedure¦apoc.es.getRaw¦apoc.es.getRaw(host :: STRING?, path :: STRING?, payload :: ANY?) :: (value :: MAP?)¦apoc.es.getRaw(host-or-port,path,payload-or-null) yield value - perform a raw GET operation on elastic search¦false¦xref::database-integration/elasticsearch.adoc
¦procedure¦apoc.es.post¦apoc.es.post(host :: STRING?, index :: STRING?, type :: STRING?, query :: ANY?, payload = {} :: MAP?) :: (value :: MAP?)¦apoc.es.post(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a POST operation on elastic search¦false¦xref::database-integration/elasticsearch.adoc
¦procedure¦apoc.es.postRaw¦apoc.es.postRaw(host :: STRING?, path :: STRING?, payload :: ANY?) :: (value :: MAP?)¦apoc.es.postRaw(host-or-port,path,payload-or-null) yield value - perform a raw POST operation on elastic search¦false¦xref::database-integration/elasticsearch.adoc
¦procedure¦apoc.es.put¦apoc.es.put(host :: STRING?, index :: STRING?, type :: STRING?, id :: STRING?, query :: ANY?, payload = {} :: MAP?) :: (value :: MAP?)¦apoc.es.put(host-or-port,index-or-null,type-or-null,id-or-null,query-or-null,payload-or-null) yield value - perform a PUT operation on elastic search¦false¦xref::database-integration/elasticsearch.adoc
¦procedure¦apoc.es.query¦apoc.es.query(host :: STRING?, index :: STRING?, type :: STRING?, query :: ANY?, payload :: ANY?) :: (value :: MAP?)¦apoc.es.query(host-or-port,index-or-null,type-or-null,query-or-null,payload-or-null) yield value - perform a SEARCH operation on elastic search¦false¦xref::database-integration/elasticsearch.adoc
¦procedure¦apoc.es.stats¦apoc.es.stats(host :: STRING?) :: (value :: MAP?)¦apoc.es.stats(host-url-Key) - elastic search statistics¦false¦xref::database-integration/elasticsearch.adoc
¦procedure¦apoc.export.xls.all¦apoc.export.xls.all(file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)¦apoc.export.xls.all(file,config) - exports whole database as xls to the provided file¦false¦
¦procedure¦apoc.export.xls.data¦apoc.export.xls.data(nodes :: LIST? OF NODE?, rels :: LIST? OF RELATIONSHIP?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)¦apoc.export.xls.data(nodes,rels,file,config) - exports given nodes and relationships as xls to the provided file¦false¦
¦procedure¦apoc.export.xls.graph¦apoc.export.xls.graph(graph :: MAP?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)¦apoc.export.xls.graph(graph,file,config) - exports given graph object as xls to the provided file¦false¦
¦procedure¦apoc.export.xls.query¦apoc.export.xls.query(query :: STRING?, file :: STRING?, config :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)¦apoc.export.xls.query(query,file,{config,...,params:\{params}}) - exports results from the cypher statement as xls to the provided file¦false¦
¦procedure¦apoc.generate.ba¦apoc.generate.ba(noNodes :: INTEGER?, edgesPerNode :: INTEGER?, label :: STRING?, type :: STRING?) :: VOID¦apoc.generate.ba(noNodes, edgesPerNode, label, type) - generates a random graph according to the Barabasi-Albert model¦false¦xref::graph-updates/graph-generators.adoc
¦procedure¦apoc.generate.complete¦apoc.generate.complete(noNodes :: INTEGER?, label :: STRING?, type :: STRING?) :: VOID¦apoc.generate.complete(noNodes, label, type) - generates a random complete graph¦false¦xref::graph-updates/graph-generators.adoc
¦procedure¦apoc.generate.er¦apoc.generate.er(noNodes :: INTEGER?, noEdges :: INTEGER?, label :: STRING?, type :: STRING?) :: VOID¦apoc.generate.er(noNodes, noEdges, label, type) - generates a random graph according to the Erdos-Renyi model¦false¦xref::graph-updates/graph-generators.adoc
¦procedure¦apoc.generate.simple¦apoc.generate.simple(degrees :: LIST? OF INTEGER?, label :: STRING?, type :: STRING?) :: VOID¦apoc.generate.simple(degrees, label, type) - generates a simple random graph according to the given degree distribution¦false¦xref::graph-updates/graph-generators.adoc
¦procedure¦apoc.generate.ws¦apoc.generate.ws(noNodes :: INTEGER?, degree :: INTEGER?, beta :: FLOAT?, label :: STRING?, type :: STRING?) :: VOID¦apoc.generate.ws(noNodes, degree, beta, label, type) - generates a random graph according to the Watts-Strogatz model¦false¦xref::graph-updates/graph-generators.adoc
¦procedure¦apoc.gephi.add¦apoc.gephi.add(urlOrKey :: STRING?, workspace :: STRING?, data :: ANY?, weightproperty = null :: STRING?, exportproperties = [] :: LIST? OF STRING?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: STRING?)¦apoc.gephi.add(url-or-key, workspace, data, weightproperty, ['exportproperty']) | streams passed in data to Gephi¦false¦xref::export/gephi.adoc
¦procedure¦apoc.get.nodes¦apoc.get.nodes(nodes :: ANY?) :: (node :: NODE?)¦apoc.get.nodes(node|id|[ids]) - quickly returns all nodes with these id's¦false¦
¦procedure¦apoc.get.rels¦apoc.get.rels(relationships :: ANY?) :: (rel :: RELATIONSHIP?)¦apoc.get.rels(rel|id|[ids]) - quickly returns all relationships with these id's¦false¦
¦procedure¦apoc.load.csv¦apoc.load.csv(url :: STRING?, config = {} :: MAP?) :: (lineNo :: INTEGER?, list :: LIST? OF ANY?, strings :: LIST? OF STRING?, map :: MAP?, stringMap :: MAP?)¦apoc.load.csv('url',\{config}) YIELD lineNo, list, map - load CSV from URL as stream of values,
 config contains any of: {skip:1,limit:5,header:false,sep:'TAB',ignore:['tmp'],nullValues:['na'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false}}¦false¦xref::import/load-csv.adoc
¦procedure¦apoc.load.csvParams¦apoc.load.csvParams(url :: STRING?, httpHeaders :: MAP?, payload :: STRING?, config = {} :: MAP?) :: (lineNo :: INTEGER?, list :: LIST? OF ANY?, strings :: LIST? OF STRING?, map :: MAP?, stringMap :: MAP?)¦apoc.load.csvParams('url', {httpHeader: value}, payload, \{config}) YIELD lineNo, list, map - load from CSV URL (e.g. web-api) while sending headers / payload to load CSV from URL as stream of values,
 config contains any of: {skip:1,limit:5,header:false,sep:'TAB',ignore:['tmp'],nullValues:['na'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false}}¦false¦
¦procedure¦apoc.load.directory¦apoc.load.directory(pattern = * :: STRING?, urlDir =  :: STRING?, config = {} :: MAP?) :: (value :: STRING?)¦apoc.load.directory('pattern', 'urlDir', \{config}) YIELD value - Loads list of all files in the folder specified by the parameter urlDir satisfying the given pattern. If the parameter urlDir is not specified or empty, the files of the import folder are loaded instead.¦false¦
¦procedure¦apoc.load.directory.async.add¦apoc.load.directory.async.add(name :: STRING?, cypher :: STRING?, pattern = * :: STRING?, urlDir =  :: STRING?, config = {} :: MAP?) :: (name :: STRING?, status :: STRING?, pattern :: STRING?, cypher :: STRING?, urlDir :: STRING?, config :: MAP?, error :: STRING?)¦apoc.load.directory.async.add(name, cypher, pattern, urlDir, {}) YIELD name, status, pattern, cypher, urlDir, config, error - Adds or replaces a folder listener with a specific name, which is triggered for all files with the given pattern and executes the specified Cypher query when triggered. Returns a list of all listeners. It is possible to specify the event type in the config parameter.¦false¦
¦procedure¦apoc.load.directory.async.list¦apoc.load.directory.async.list() :: (name :: STRING?, status :: STRING?, pattern :: STRING?, cypher :: STRING?, urlDir :: STRING?, config :: MAP?, error :: STRING?)¦apoc.load.directory.async.list() YIELD name, status, pattern, cypher, urlDir, config, error - Lists all folder listeners¦false¦
¦procedure¦apoc.load.directory.async.remove¦apoc.load.directory.async.remove(name :: STRING?) :: (name :: STRING?, status :: STRING?, pattern :: STRING?, cypher :: STRING?, urlDir :: STRING?, config :: MAP?, error :: STRING?)¦apoc.load.directory.async.remove(name) YIELD name, status, pattern, cypher, urlDir, config, error - Removes a folder listener by name and returns all remaining listeners, if any¦false¦
¦procedure¦apoc.load.directory.async.removeAll¦apoc.load.directory.async.removeAll() :: (name :: STRING?, status :: STRING?, pattern :: STRING?, cypher :: STRING?, urlDir :: STRING?, config :: MAP?, error :: STRING?)¦apoc.load.directory.async.removeAll() - Removes all folder listeners¦false¦
¦procedure¦apoc.load.driver¦apoc.load.driver(driverClass :: STRING?) :: VOID¦apoc.load.driver('org.apache.derby.jdbc.EmbeddedDriver') register JDBC driver of source database¦false¦
¦procedure¦apoc.load.html¦apoc.load.html(url :: STRING?, query = {} :: MAP?, config = {} :: MAP?) :: (value :: MAP?)¦apoc.load.html('url',{name: jquery, name2: jquery}, config) YIELD value - Load Html page and return the result as a Map¦false¦
¦procedure¦apoc.load.jdbc¦apoc.load.jdbc(jdbc :: STRING?, tableOrSql :: STRING?, params = [] :: LIST? OF ANY?, config = {} :: MAP?) :: (row :: MAP?)¦apoc.load.jdbc('key or url','table or statement', params, config) YIELD row - load from relational database, from a full table or a sql statement¦false¦xref::database-integration/load-jdbc.adoc
¦procedure¦apoc.load.jdbcUpdate¦apoc.load.jdbcUpdate(jdbc :: STRING?, query :: STRING?, params = [] :: LIST? OF ANY?, config = {} :: MAP?) :: (row :: MAP?)¦apoc.load.jdbcUpdate('key or url','statement',[params],config) YIELD row - update relational database, from a SQL statement with optional parameters¦false¦xref::database-integration/load-jdbc.adoc
¦procedure¦apoc.load.ldap¦apoc.load.ldap(connection :: ANY?, search :: MAP?) :: (entry :: MAP?)¦apoc.load.ldap("key" or \{connectionMap},\{searchMap}) Load entries from an ldap source (yield entry)¦false¦
¦procedure¦apoc.load.xls¦apoc.load.xls(url :: STRING?, selector :: STRING?, config = {} :: MAP?) :: (lineNo :: INTEGER?, list :: LIST? OF ANY?, map :: MAP?)¦apoc.load.xls('url','selector',\{config}) YIELD lineNo, list, map - load XLS fom URL as stream of row values,
 config contains any of: {skip:1,limit:5,header:false,ignore:['tmp'],arraySep:';',mapping:{years:{type:'int',arraySep:'-',array:false,name:'age',ignore:false, dateFormat:'iso_date', dateParse:['dd-MM-yyyy']}}¦false¦
¦procedure¦apoc.log.debug¦apoc.log.debug(message :: STRING?, params = [] :: LIST? OF ANY?) :: VOID¦apoc.log.debug(message, params) - logs debug message¦false¦
¦procedure¦apoc.log.error¦apoc.log.error(message :: STRING?, params = [] :: LIST? OF ANY?) :: VOID¦apoc.log.error(message, params) - logs error message¦false¦
¦procedure¦apoc.log.info¦apoc.log.info(message :: STRING?, params = [] :: LIST? OF ANY?) :: VOID¦apoc.log.info(message, params) - logs info message¦false¦
¦procedure¦apoc.log.warn¦apoc.log.warn(message :: STRING?, params = [] :: LIST? OF ANY?) :: VOID¦apoc.log.warn(message, params) - logs warn message¦false¦
¦procedure¦apoc.metrics.get¦apoc.metrics.get(metricName :: STRING?, config = {} :: MAP?) :: (timestamp :: INTEGER?, metric :: STRING?, map :: MAP?)¦apoc.metrics.get(metricName, {}) - retrieve a system metric by its metric name. Additional configuration options may be passed matching the options available for apoc.load.csv.¦false¦
¦procedure¦apoc.metrics.list¦apoc.metrics.list() :: (name :: STRING?, lastUpdated :: INTEGER?)¦apoc.metrics.list() - get a list of available metrics¦false¦
¦procedure¦apoc.metrics.storage¦apoc.metrics.storage(directorySetting :: STRING?) :: (setting :: STRING?, freeSpaceBytes :: INTEGER?, totalSpaceBytes :: INTEGER?, usableSpaceBytes :: INTEGER?, percentFree :: FLOAT?)¦apoc.metrics.storage(directorySetting) - retrieve storage metrics about the devices Neo4j uses for data storage. directorySetting may be any valid neo4j directory setting name, such as 'server.directories.data'.  If null is provided as a directorySetting, you will get back all available directory settings.  For a list of available directory settings, see the Neo4j operations manual reference on configuration settings.   Directory settings are **not** paths, they are a neo4j.conf setting key name¦false¦
¦procedure¦apoc.model.jdbc¦apoc.model.jdbc(jdbc :: STRING?, config = {} :: MAP?) :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)¦apoc.model.jdbc('key or url', {schema:'<schema>', write: <true/false>, filters: { tables:[], views: [], columns: []}) YIELD nodes, relationships - load schema from relational database¦false¦xref::database-integration/database-modeling.adoc
¦procedure¦apoc.mongo.aggregate¦apoc.mongo.aggregate(uri :: STRING?, pipeline :: LIST? OF MAP?, config = {} :: MAP?) :: (value :: MAP?)¦apoc.mongo.aggregate(uri, pipeline, $config) yield value - perform an aggregate operation on mongodb collection¦false¦xref::database-integration/mongo.adoc
¦procedure¦apoc.mongo.count¦apoc.mongo.count(uri :: STRING?, query :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)¦apoc.mongo.count(uri, query, $config) yield value - perform a count operation on mongodb collection¦false¦xref::database-integration/mongo.adoc
¦procedure¦apoc.mongo.delete¦apoc.mongo.delete(uri :: STRING?, query :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)¦apoc.mongo.delete(uri, query, $config) - delete the given documents from the mongodb collection and returns the number of affected documents¦false¦xref::database-integration/mongo.adoc
¦procedure¦apoc.mongo.find¦apoc.mongo.find(uri :: STRING?, query = null :: ANY?, config = {} :: MAP?) :: (value :: MAP?)¦apoc.mongo.find(uri, query, $config) yield value - perform a find operation on mongodb collection¦false¦xref::database-integration/mongo.adoc
¦procedure¦apoc.mongo.insert¦apoc.mongo.insert(uri :: STRING?, documents :: LIST? OF ANY?, config = {} :: MAP?) :: VOID¦apoc.mongo.insert(uri, documents, $config) yield value - inserts the given documents into the mongodb collection¦false¦xref::database-integration/mongo.adoc
¦procedure¦apoc.mongo.update¦apoc.mongo.update(uri :: STRING?, query :: ANY?, update :: ANY?, config = {} :: MAP?) :: (value :: INTEGER?)¦apoc.mongo.update(uri, query, update, $config) - updates the given documents from the mongodb collection and returns the number of affected documents¦false¦xref::database-integration/mongo.adoc
¦procedure¦apoc.mongodb.get.byObjectId¦apoc.mongodb.get.byObjectId(host :: STRING?, db :: STRING?, collection :: STRING?, objectIdValue :: STRING?, config = {} :: MAP?) :: (value :: MAP?)¦apoc.mongodb.get.byObjectId(hostOrKey, db, collection, objectIdValue, config(default:{})) - get the document by Object id value¦false¦xref::database-integration/mongodb.adoc
¦procedure¦apoc.monitor.ids¦apoc.monitor.ids() :: (nodeIds :: INTEGER?, relIds :: INTEGER?, propIds :: INTEGER?, relTypeIds :: INTEGER?)¦apoc.monitor.ids() returns the object ids in use for this neo4j instance¦false¦xref::database-introspection/monitoring.adoc
¦procedure¦apoc.monitor.kernel¦apoc.monitor.kernel() :: (readOnly :: BOOLEAN?, kernelVersion :: STRING?, storeId :: STRING?, kernelStartTime :: STRING?, databaseName :: STRING?, storeLogVersion :: INTEGER?, storeCreationDate :: STRING?)¦apoc.monitor.kernel() returns informations about the neo4j kernel¦false¦xref::database-introspection/monitoring.adoc
¦procedure¦apoc.monitor.store¦apoc.monitor.store() :: (logSize :: INTEGER?, stringStoreSize :: INTEGER?, arrayStoreSize :: INTEGER?, relStoreSize :: INTEGER?, propStoreSize :: INTEGER?, totalStoreSize :: INTEGER?, nodeStoreSize :: INTEGER?)¦apoc.monitor.store() returns informations about the sizes of the different parts of the neo4j graph store¦false¦xref::database-introspection/monitoring.adoc
¦procedure¦apoc.monitor.tx¦apoc.monitor.tx() :: (rolledBackTx :: INTEGER?, peakTx :: INTEGER?, lastTxId :: INTEGER?, currentOpenedTx :: INTEGER?, totalOpenedTx :: INTEGER?, totalTx :: INTEGER?)¦apoc.monitor.tx() returns informations about the neo4j transaction manager¦false¦xref::database-introspection/monitoring.adoc
¦procedure¦apoc.nlp.aws.entities.graph¦apoc.nlp.aws.entities.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)¦Creates a (virtual) entity graph for provided text¦false¦
¦procedure¦apoc.nlp.aws.entities.stream¦apoc.nlp.aws.entities.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)¦Returns a stream of entities for provided text¦false¦
¦procedure¦apoc.nlp.aws.keyPhrases.graph¦apoc.nlp.aws.keyPhrases.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)¦Creates a (virtual) key phrases graph for provided text¦false¦
¦procedure¦apoc.nlp.aws.keyPhrases.stream¦apoc.nlp.aws.keyPhrases.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)¦Returns a stream of key phrases for provided text¦false¦
¦procedure¦apoc.nlp.aws.sentiment.graph¦apoc.nlp.aws.sentiment.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)¦Creates a (virtual) sentiment graph for provided text¦false¦
¦procedure¦apoc.nlp.aws.sentiment.stream¦apoc.nlp.aws.sentiment.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)¦Returns stream of sentiment for items in provided text¦false¦
¦procedure¦apoc.nlp.azure.entities.graph¦apoc.nlp.azure.entities.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)¦Creates a (virtual) entity graph for provided text¦true¦
¦procedure¦apoc.nlp.azure.entities.stream¦apoc.nlp.azure.entities.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)¦Provides a entity analysis for provided text¦true¦
¦procedure¦apoc.nlp.azure.keyPhrases.graph¦apoc.nlp.azure.keyPhrases.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)¦Creates a (virtual) key phrase graph for provided text¦true¦
¦procedure¦apoc.nlp.azure.keyPhrases.stream¦apoc.nlp.azure.keyPhrases.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)¦Provides a entity analysis for provided text¦true¦
¦procedure¦apoc.nlp.azure.sentiment.graph¦apoc.nlp.azure.sentiment.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)¦Creates a (virtual) sentiment graph for provided text¦true¦
¦procedure¦apoc.nlp.azure.sentiment.stream¦apoc.nlp.azure.sentiment.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)¦Provides a sentiment analysis for provided text¦true¦
¦procedure¦apoc.nlp.gcp.classify.graph¦apoc.nlp.gcp.classify.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)¦Classifies a document into categories.¦false¦
¦procedure¦apoc.nlp.gcp.classify.stream¦apoc.nlp.gcp.classify.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)¦Classifies a document into categories.¦false¦
¦procedure¦apoc.nlp.gcp.entities.graph¦apoc.nlp.gcp.entities.graph(source :: ANY?, config = {} :: MAP?) :: (graph :: MAP?)¦Creates a (virtual) entity graph for provided text¦false¦
¦procedure¦apoc.nlp.gcp.entities.stream¦apoc.nlp.gcp.entities.stream(source :: ANY?, config = {} :: MAP?) :: (node :: NODE?, value :: MAP?, error :: MAP?)¦Returns a stream of entities for provided text¦false¦
¦procedure¦apoc.systemdb.execute¦apoc.systemdb.execute(DDL commands, either a string or a list of strings :: ANY?, params = {} :: MAP?) :: (row :: MAP?)¦¦false¦
¦procedure¦apoc.systemdb.export.metadata¦apoc.systemdb.export.metadata(config = {} :: MAP?) :: (file :: STRING?, source :: STRING?, format :: STRING?, nodes :: INTEGER?, relationships :: INTEGER?, properties :: INTEGER?, time :: INTEGER?, rows :: INTEGER?, batchSize :: INTEGER?, batches :: INTEGER?, done :: BOOLEAN?, data :: ANY?)¦¦false¦
¦procedure¦apoc.systemdb.graph¦apoc.systemdb.graph() :: (nodes :: LIST? OF NODE?, relationships :: LIST? OF RELATIONSHIP?)¦¦false¦
¦procedure¦apoc.ttl.expire¦apoc.ttl.expire(node :: NODE?, time :: INTEGER?, timeUnit :: STRING?) :: VOID¦CALL apoc.ttl.expire(node,time,'time-unit') - expire node at specified time by setting :TTL label and `ttl` property¦false¦xref::graph-updates/ttl.adoc
¦procedure¦apoc.ttl.expireIn¦apoc.ttl.expireIn(node :: NODE?, timeDelta :: INTEGER?, timeUnit :: STRING?) :: VOID¦CALL apoc.ttl.expireIn(node,timeDelta,'time-unit') - expire node after specified length of time time by setting :TTL label and `ttl` property¦false¦xref::graph-updates/ttl.adoc
¦procedure¦apoc.util.sleep¦apoc.util.sleep(duration :: INTEGER?) :: VOID¦apoc.util.sleep(<duration>) | sleeps for <duration> millis, transaction termination is honored¦true¦
¦procedure¦apoc.util.validate¦apoc.util.validate(predicate :: BOOLEAN?, message :: STRING?, params :: LIST? OF ANY?) :: VOID¦apoc.util.validate(predicate, message, params) | if the predicate yields to true raise an exception¦true¦
¦procedure¦apoc.uuid.install¦apoc.uuid.install(label :: STRING?, config = {} :: MAP?) :: (batchComputationResult :: MAP?, label :: STRING?, installed :: BOOLEAN?, properties :: MAP?)¦CALL apoc.uuid.install(label, {addToExistingNodes: true/false, uuidProperty: 'uuid'}) yield label, installed, properties, batchComputationResult | it will add the uuid transaction handler
for the provided `label` and `uuidProperty`, in case the UUID handler is already present it will be replaced by the new one¦false¦xref::graph-updates/uuid.adoc
¦procedure¦apoc.uuid.list¦apoc.uuid.list() :: (label :: STRING?, installed :: BOOLEAN?, properties :: MAP?)¦CALL apoc.uuid.list() yield label, installed, properties | provides a list of all the uuid handlers installed with the related configuration¦false¦xref::graph-updates/uuid.adoc
¦procedure¦apoc.uuid.remove¦apoc.uuid.remove(label :: STRING?) :: (label :: STRING?, installed :: BOOLEAN?, properties :: MAP?)¦CALL apoc.uuid.remove(label) yield label, installed, properties | remove previously added uuid handler and returns uuid information. All the existing uuid properties are left as-is¦false¦xref::graph-updates/uuid.adoc
¦procedure¦apoc.uuid.removeAll¦apoc.uuid.removeAll() :: (label :: STRING?, installed :: BOOLEAN?, properties :: MAP?)¦CALL apoc.uuid.removeAll() yield label, installed, properties | it removes all previously added uuid handlers and returns uuids information. All the existing uuid properties are left as-is¦false¦xref::graph-updates/uuid.adoc
¦function¦apoc.data.email¦apoc.data.email(email_address :: STRING?) :: (MAP?)¦apoc.data.email('email_address') as {personal,user,domain} - extract the personal name, user and domain as a map¦false¦
¦function¦apoc.static.get¦apoc.static.get(key :: STRING?) :: (ANY?)¦apoc.static.get(name) - returns statically stored value from config (apoc.static.<key>) or server lifetime storage¦false¦xref::misc/static-values.adoc
¦function¦apoc.static.getAll¦apoc.static.getAll(prefix :: STRING?) :: (MAP?)¦apoc.static.getAll(prefix) - returns statically stored values from config (apoc.static.<prefix>.*) or server lifetime storage¦false¦xref::misc/static-values.adoc
¦function¦apoc.trigger.nodesByLabel¦apoc.trigger.nodesByLabel(labelEntries :: ANY?, label :: STRING?) :: (LIST? OF ANY?)¦¦false¦xref::background-operations/triggers.adoc
¦function¦apoc.trigger.propertiesByKey¦apoc.trigger.propertiesByKey(propertyEntries :: MAP?, key :: STRING?) :: (LIST? OF ANY?)¦¦false¦xref::background-operations/triggers.adoc
¦function¦apoc.ttl.config¦apoc.ttl.config() :: (MAP?)¦¦false¦xref::graph-updates/ttl.adoc
¦function¦apoc.util.compress¦apoc.util.compress(data :: STRING?, config = {} :: MAP?) :: (BYTEARRAY?)¦apoc.util.compress(string, \{config}) | return a compressed byte[] in various format from a string¦true¦
¦function¦apoc.util.decompress¦apoc.util.decompress(data :: BYTEARRAY?, config = {} :: MAP?) :: (STRING?)¦apoc.util.decompress(compressed, \{config}) | return a string from a compressed byte[] in various format¦true¦
¦function¦apoc.util.md5¦apoc.util.md5(values :: LIST? OF ANY?) :: (STRING?)¦apoc.util.md5([values]) | computes the md5 of the concatenation of all string values of the list¦true¦xref::misc/text-functions.adoc#text-functions-hashing
¦function¦apoc.util.sha1¦apoc.util.sha1(values :: LIST? OF ANY?) :: (STRING?)¦apoc.util.sha1([values]) | computes the sha1 of the concatenation of all string values of the list¦true¦xref::misc/text-functions.adoc#text-functions-hashing
¦function¦apoc.util.sha256¦apoc.util.sha256(values :: LIST? OF ANY?) :: (STRING?)¦apoc.util.sha256([values]) | computes the sha256 of the concatenation of all string values of the list¦true¦
¦function¦apoc.util.sha384¦apoc.util.sha384(values :: LIST? OF ANY?) :: (STRING?)¦apoc.util.sha384([values]) | computes the sha384 of the concatenation of all string values of the list¦true¦
¦function¦apoc.util.sha512¦apoc.util.sha512(values :: LIST? OF ANY?) :: (STRING?)¦apoc.util.sha512([values]) | computes the sha512 of the concatenation of all string values of the list¦true¦
¦function¦apoc.util.validatePredicate¦apoc.util.validatePredicate(predicate :: BOOLEAN?, message :: STRING?, params :: LIST? OF ANY?) :: (BOOLEAN?)¦apoc.util.validatePredicate(predicate, message, params) | if the predicate yields to true raise an exception else returns true, for use inside WHERE subclauses¦true¦
