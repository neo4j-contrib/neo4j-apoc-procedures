The `apoc.import.json` procedure can be used to import JSON files created by the xref::overview/apoc.export/index.adoc[`apoc.export.json.*`] procedures.

`all.json` contains a subset of Neo4j's movies graph, and was generated by xref::overview/apoc.export/apoc.export.json.all.adoc[].

.all.json
[source,json]
----
include::example$data/exportJSON/all.json[leveloffset]
----

We can import this file using `apoc.import.json`.

[source,cypher]
----
CALL apoc.import.json("file:///all.json")
----

.Results
[opts=header]
|===
| file               | source | format | nodes | relationships | properties | time | rows | batchSize | batches | done | data
| "file:///all.json" | "file" | "json" | 3     | 1             | 15         | 105  | 4    | -1        | 0       | TRUE | NULL
|===


== Binary file

You can also import a file from a binary `byte[]` not compressed (default value, with config {compression: `NONE`})
or a compressed file (allowed compression algos are: `GZIP`, `BZIP2`, `DEFLATE`, `BLOCK_LZ4`, `FRAMED_SNAPPY`). That is:


[source,cypher]
----
CALL apoc.import.json(`binaryFileNotCompressed`, {compression: 'NONE'})
----

or:

[source,cypher]
----
CALL apoc.import.json(`binaryGzipByteArray`, {compression: 'GZIP'})
----

For example, this one works well with xref::overview/apoc.util/apoc.util.compress.adoc[apoc.util.compress] function:

[source,cypher]
----
WITH apoc.util.compress('{"type":"node","id":"2","labels":["User"],"properties":{"age":12}}', {compression: 'DEFLATE'}) AS jsonCompressed
CALL apoc.import.json(jsonCompressed, {compression: 'DEFLATE'}) 
YIELD source, format, nodes, relationships, properties
RETURN source, format, nodes, relationships, properties
----

.Results
[opts=header]
|===
| source | format | nodes | relationships | properties 
| "binary" | "json" | 1     | 0             | 2 
|===
